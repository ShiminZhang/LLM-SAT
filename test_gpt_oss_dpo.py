#!/usr/bin/env python3
"""
ä½¿ç”¨gpt-oss-20bæ¨¡å‹çš„DPO+LoRAæµ‹è¯•è„šæœ¬
"""
import torch
import logging
from transformers import AutoTokenizer, AutoModelForCausalLM
from trl import DPOTrainer, DPOConfig
from peft import LoraConfig, get_peft_model, TaskType
from datasets import Dataset
import json
import wandb
import os
import psutil
import time
import gc
from data_manager import DataManager

# åˆå§‹åŒ–wandb
def init_wandb(lora_r=16, lora_alpha=32, lora_dropout=0.1, batch_size=1):
    """åˆå§‹åŒ–wandb"""
    try:
        # ä»ç¯å¢ƒå˜é‡æˆ–ç›´æ¥è®¾ç½®APIå¯†é’¥
        api_key = os.getenv("WANDB_API_KEY", "2b12ed4713d66c27d43040761ff1e0574c7a7ef2")
        wandb.login(key=api_key)
        
        # åˆå§‹åŒ–wandbé¡¹ç›®
        wandb.init(
            project="gpt-oss-dpo",
            name="dpo-lora-training",
            config={
                "model": f"gpt-oss-20b_bs{batch_size}_r{lora_r}_alpha{lora_alpha}_dropout{lora_dropout}",
                "method": "DPO+LoRA",
                "learning_rate": 5e-6,
                "batch_size": batch_size,
                "epochs": 1,
                "beta": 0.1,
                "lora_r": lora_r,
                "lora_alpha": lora_alpha,
                "lora_dropout": lora_dropout,
            }
        )
        logger.info("âœ… Wandbåˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        logger.warning(f"âš ï¸ Wandbåˆå§‹åŒ–å¤±è´¥: {e}")
        return False
# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_gpu_memory_info():
    """è·å–GPUæ˜¾å­˜ä¿¡æ¯"""
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
        gpu_allocated = torch.cuda.memory_allocated(0) / 1024**3  # GB
        gpu_reserved = torch.cuda.memory_reserved(0) / 1024**3  # GB
        gpu_free = gpu_memory - gpu_reserved
        return {
            "total": gpu_memory,
            "allocated": gpu_allocated,
            "reserved": gpu_reserved,
            "free": gpu_free,
            "utilization": (gpu_reserved / gpu_memory) * 100
        }
    return None

def force_cleanup_gpu():
    """å¼ºåˆ¶æ¸…ç†GPUæ˜¾å­˜"""
    if torch.cuda.is_available():
        # æ¸…ç†PyTorchç¼“å­˜
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()
        
        # æ¸…ç†Pythonåƒåœ¾å›æ”¶
        gc.collect()
        
        # å¼ºåˆ¶åŒæ­¥ï¼Œç¡®ä¿æ¸…ç†å®Œæˆ
        torch.cuda.synchronize()
        
        # å†æ¬¡æ¸…ç†
        torch.cuda.empty_cache()
        gc.collect()
        
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©ç³»ç»Ÿå¤„ç†
        time.sleep(1)

def log_memory_usage(stage_name, wandb_enabled=False):
    """è®°å½•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    gpu_info = get_gpu_memory_info()
    cpu_memory = psutil.virtual_memory()
    
    memory_info = {
        f"gpu_total_gb": gpu_info["total"] if gpu_info else 0,
        f"gpu_allocated_gb": gpu_info["allocated"] if gpu_info else 0,
        f"gpu_reserved_gb": gpu_info["reserved"] if gpu_info else 0,
        f"gpu_free_gb": gpu_info["free"] if gpu_info else 0,
        f"gpu_utilization_pct": gpu_info["utilization"] if gpu_info else 0,
        f"cpu_memory_used_pct": cpu_memory.percent,
        f"cpu_memory_available_gb": cpu_memory.available / 1024**3,
        "stage": stage_name
    }
    
    logger.info(f"ğŸ“Š {stage_name} - GPU: {gpu_info['utilization']:.1f}% used, {gpu_info['free']:.1f}GB free" if gpu_info else f"ğŸ“Š {stage_name} - CPU: {cpu_memory.percent:.1f}% used")
    
    if wandb_enabled:
        wandb.log(memory_info)
    
    return memory_info

    
    # ä¸ºäº†æµ‹è¯•ä¸åŒbatch sizeï¼Œæˆ‘ä»¬é‡å¤æ•°æ®
    extended_data = []
    for i in range(5):  # é‡å¤5æ¬¡ï¼Œæ€»å…±75ä¸ªæ ·æœ¬
        for item in base_data:
            extended_data.append(item)
    
    return extended_data

def test_batch_sizes(lora_r=16, lora_alpha=32, lora_dropout=0.1, batch_size=1):
    """æµ‹è¯•ä¸åŒbatch sizeå¯¹GPUæ˜¾å­˜çš„å½±å“"""
    logger.info("ğŸš€ å¼€å§‹batch sizeæ˜¾å­˜æµ‹è¯•...")
    
    # åˆå§‹åŒ–wandb
    wandb_enabled = init_wandb(lora_r, lora_alpha, lora_dropout, batch_size)
    
    # ä½¿ç”¨æœ¬åœ°gpt-oss-20bæ¨¡å‹
    model_name = "./models/gpt-oss-20b"
    logger.info(f"åŠ è½½æ¨¡å‹: {model_name}")
    
    # å¼ºåˆ¶æ¸…ç†æ˜¾å­˜
    force_cleanup_gpu()
    
    # è®°å½•åˆå§‹å†…å­˜çŠ¶æ€
    log_memory_usage("åˆå§‹çŠ¶æ€", wandb_enabled)
    
    # åŠ è½½tokenizerå’Œæ¨¡å‹
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.bfloat16,
        device_map="auto",
        trust_remote_code=True,
    )
    
    # è®°å½•æ¨¡å‹åŠ è½½åå†…å­˜çŠ¶æ€
    log_memory_usage("æ¨¡å‹åŠ è½½å", wandb_enabled)
    
    # è®¾ç½®LoRA
    lora_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        r=lora_r,
        lora_alpha=lora_alpha,
        lora_dropout=lora_dropout,
        target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
        bias="none",
    )
    
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()
    
    # è®°å½•LoRAåº”ç”¨åå†…å­˜çŠ¶æ€
    log_memory_usage("LoRAåº”ç”¨å", wandb_enabled)
    
    # å‡†å¤‡æ•°æ®
    raw_data = DataManager().get_data(1000)
    train_dataset = Dataset.from_list(raw_data)
    logger.info(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(train_dataset)} ä¸ªæ ·æœ¬")
    # input("æŒ‰å›è½¦é”®ç»§ç»­æµ‹è¯•ä¸åŒbatch size...")  # wait for enter to continue
    # æµ‹è¯•ä¸åŒçš„batch size
    results = []
    
    logger.info(f"ğŸ§ª æµ‹è¯• batch_size = {batch_size}")
    
    try:
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        gc.collect()
        
        # è®°å½•æµ‹è¯•å‰å†…å­˜çŠ¶æ€
        memory_before = log_memory_usage(f"batch_{batch_size}_before", wandb_enabled)
        
        # DPOé…ç½®
        dpo_config = DPOConfig(
            output_dir=f"./gpt_oss_dpo_output_bs{batch_size}",
            num_train_epochs=1,
            per_device_train_batch_size=batch_size,
            per_device_eval_batch_size=batch_size,
            warmup_steps=2,
            logging_steps=1,
            save_steps=50,
            save_strategy="steps",
            remove_unused_columns=False,
            max_length=512,
            beta=0.1,
            learning_rate=5e-6,
            lr_scheduler_type="cosine",
            gradient_accumulation_steps=1,
            bf16=True,
            dataloader_num_workers=0,
            padding_value=tokenizer.pad_token_id,
        )
        
        # åˆ›å»ºDPOè®­ç»ƒå™¨
        dpo_trainer = DPOTrainer(
            model=model,
            ref_model=None,
            args=dpo_config,
            train_dataset=train_dataset,
        )
        
        # è®°å½•è®­ç»ƒå™¨åˆ›å»ºåå†…å­˜çŠ¶æ€
        memory_trainer = log_memory_usage(f"batch_{batch_size}_trainer_created", wandb_enabled)
        
        # å¼€å§‹è®­ç»ƒ
        start_time = time.time()
        dpo_trainer.train()
        training_time = time.time() - start_time
        
        # è®°å½•è®­ç»ƒåå†…å­˜çŠ¶æ€
        memory_after = log_memory_usage(f"batch_{batch_size}_after_training", wandb_enabled)
        
        # è®°å½•ç»“æœ
        result = {
            "lora_r": lora_r,
            "lora_alpha": lora_alpha,
            "lora_dropout": lora_dropout,
            "batch_size": batch_size,
            "training_time": training_time,
            "memory_before": memory_before,
            "memory_trainer": memory_trainer,
            "memory_after": memory_after,
            "success": True
        }
        results.append(result)
        
        logger.info(f"âœ… Batch size {batch_size} è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
        
        # æ¸…ç†å†…å­˜
        del dpo_trainer
        torch.cuda.empty_cache()
        gc.collect()
        
    except Exception as e:
        logger.error(f"âŒ Batch size {batch_size} è®­ç»ƒå¤±è´¥: {e}")
        result = {
            "batch_size": batch_size,
            "error": str(e),
            "success": False
        }
        results.append(result)
        
        # æ¸…ç†å†…å­˜
        torch.cuda.empty_cache()
        gc.collect()
    
    # è¾“å‡ºæµ‹è¯•ç»“æœæ€»ç»“
    logger.info("ğŸ“Š Batch Size æµ‹è¯•ç»“æœæ€»ç»“:")
    logger.info("=" * 80)
    for result in results:
        if result["success"]:
            logger.info(f"Batch Size {result['batch_size']:2d}: âœ… æˆåŠŸ - "
                       f"è®­ç»ƒæ—¶é—´: {result['training_time']:6.2f}s - "
                       f"GPUåˆ©ç”¨ç‡: {result['memory_after']['gpu_utilization_pct']:5.1f}% - "
                       f"GPUä½¿ç”¨: {result['memory_after']['gpu_reserved_gb']:5.1f}GB")
        else:
            logger.info(f"Batch Size {result['batch_size']:2d}: âŒ å¤±è´¥ - {result['error']}")
    
    # è®°å½•åˆ°wandb
    if wandb_enabled:
        for result in results:
            if result["success"]:
                wandb.log({
                    "batch_size": result["batch_size"],
                    "training_time": result["training_time"],
                    "gpu_utilization_pct": result["memory_after"]["gpu_utilization_pct"],
                    "gpu_reserved_gb": result["memory_after"]["gpu_reserved_gb"],
                    "test_success": True
                })
            else:
                wandb.log({
                    "batch_size": result["batch_size"],
                    "error": result["error"],
                    "test_success": False
                })
    
    # æœ€ç»ˆå†…å­˜çŠ¶æ€
    log_memory_usage("æµ‹è¯•å®Œæˆ", wandb_enabled)
    
    # å½»åº•æ¸…ç†æ˜¾å­˜
    try:
        del model
        del tokenizer
        del train_dataset
        if 'dpo_trainer' in locals():
            del dpo_trainer
    except:
        pass
    
    force_cleanup_gpu()
    
    # è®°å½•æ¸…ç†åå†…å­˜çŠ¶æ€
    log_memory_usage("æ¸…ç†å", wandb_enabled)
    
    return results

def main():
    logger.info("å¼€å§‹gpt-oss-20b DPO+LoRA batch sizeæµ‹è¯•...")
    
    # æµ‹è¯•é…ç½®åˆ—è¡¨
    test_configs = [
        {"lora_r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "batch_size": 16},
        {"lora_r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "batch_size": 64},
        {"lora_r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "batch_size": 128},
        {"lora_r": 32, "lora_alpha": 64, "lora_dropout": 0.1, "batch_size": 256},
        # {"lora_r": 48, "lora_alpha": 96, "lora_dropout": 0.1, "batch_size": 16},
        {"lora_r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "batch_size": 16},
        {"lora_r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "batch_size": 64},
        {"lora_r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "batch_size": 128},
        {"lora_r": 64, "lora_alpha": 128, "lora_dropout": 0.1, "batch_size": 256},
    ]
    
    all_results = []
    
    for i, config in enumerate(test_configs):
        logger.info(f"ğŸ”„ å¼€å§‹ç¬¬ {i+1}/{len(test_configs)} æ¬¡æµ‹è¯•: LoRA r={config['lora_r']}")
        
        try:
            results = test_batch_sizes(**config)
            all_results.extend(results)
            
            # åœ¨æµ‹è¯•ä¹‹é—´æ·»åŠ ç­‰å¾…å’Œæ¸…ç†
            if i < len(test_configs) - 1:  # ä¸æ˜¯æœ€åä¸€æ¬¡æµ‹è¯•
                logger.info("â³ ç­‰å¾…5ç§’è®©æ˜¾å­˜å®Œå…¨é‡Šæ”¾...")
                time.sleep(5)
                
                # å¼ºåˆ¶æ¸…ç†æ˜¾å­˜
                force_cleanup_gpu()
                
                # è®°å½•æ¸…ç†åçŠ¶æ€
                gpu_info = get_gpu_memory_info()
                if gpu_info:
                    logger.info(f"ğŸ§¹ æ¸…ç†åæ˜¾å­˜çŠ¶æ€: {gpu_info['utilization']:.1f}% used, {gpu_info['free']:.1f}GB free")
                
        except Exception as e:
            logger.error(f"âŒ ç¬¬ {i+1} æ¬¡æµ‹è¯•å¤±è´¥: {e}")
            all_results.append({
                "config": config,
                "error": str(e),
                "success": False
            })
    
    # è¾“å‡ºæ‰€æœ‰æµ‹è¯•ç»“æœæ€»ç»“
    logger.info("ğŸ“Š æ‰€æœ‰æµ‹è¯•ç»“æœæ€»ç»“:")
    logger.info("=" * 100)
    for i, result in enumerate(all_results):
        if result.get("success", False):
            logger.info(f"æµ‹è¯• {i+1}: LoRA r={result['lora_r']}ï¼Œalpha={result['lora_alpha']}ï¼Œdropout={result['lora_dropout']}ï¼Œbatch_size={result['batch_size']} - âœ… æˆåŠŸ - "
                       f"è®­ç»ƒæ—¶é—´: {result['training_time']:6.2f}s - "
                       f"GPUåˆ©ç”¨ç‡: {result['memory_after']['gpu_utilization_pct']:5.1f}% - "
                       f"GPUä½¿ç”¨: {result['memory_after']['gpu_reserved_gb']:5.1f}GB")
        else:
            logger.info(f"æµ‹è¯• {i+1}: âŒ å¤±è´¥ - {result.get('error', 'Unknown error')}")
    
    logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")

        

if __name__ == "__main__":
    main()

