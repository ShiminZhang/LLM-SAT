{"id": "batch_req_6930b3dd2ee88190b86c5d74c713e1da", "custom_id": "req-0001", "response": {"status_code": 200, "request_id": "417ab771e79eaef69a1ab2c8aae6382a", "body": {"id": "resp_033bec64e7051eb2006930b3d00d5c819a9f64415edebdf077", "object": "response", "created_at": 1764799440, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4o-2024-08-06", "output": [{"id": "msg_033bec64e7051eb2006930b3d095f4819a90e528d327554637", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "```c\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  if (solver->stable) {\n    if (kissat_reluctant_triggered(&solver->reluctant))\n      return true;\n\n    double current_reward = solver->heuristic == 0 ? solver->mab_reward[0] : solver->mab_reward[1];\n    double max_reward = solver->heuristic == 0 ? solver->mab_reward_max[0] : solver->mab_reward_max[1];\n    if (current_reward < 0.8 * max_reward)\n      return true;\n  } else {\n    const double fast = AVERAGE(fast_glue);\n    const double slow = AVERAGE(slow_glue);\n    const double margin = (100.0 + GET_OPTION(restartmargin)) / 100.0;\n    const double limit = margin * slow;\n\n    if (limit <= fast)\n      return true;\n\n    if (AVERAGE(decision_rate) < 1.0)\n      return true;\n  }\n\n  return false;\n}\n```"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 1906, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 272, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 2178}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6930b3dd2d208190bb989a933de972f9", "custom_id": "req-0002", "response": {"status_code": 200, "request_id": "ee727df05d4e403f1dc8f42138a6705d", "body": {"id": "resp_05fe12bd9066bf42006930b3cde020819898139d8d3d6e5ed4", "object": "response", "created_at": 1764799437, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4o-2024-08-06", "output": [{"id": "msg_05fe12bd9066bf42006930b3d3c30c819889fb48f0ecca7147", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "```c\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  if (solver->stable) {\n    if (kissat_reluctant_triggered(&solver->reluctant))\n      return true;\n    const unsigned selected_heuristic = solver->heuristic;\n    const double current_reward = solver->mab_reward[selected_heuristic];\n    const double max_reward = fmax(solver->mab_reward[0], solver->mab_reward[1]);\n    if (current_reward < 0.8 * max_reward)\n      return true;\n  } else {\n    const double fast = AVERAGE(fast_glue);\n    const double slow = AVERAGE(slow_glue);\n    const double margin = (100.0 + GET_OPTION(restartmargin)) / 100.0;\n    const double limit = margin * slow;\n    if (limit <= fast)\n      return true;\n    if (AVERAGE(decision_rate) < 1.0)\n      return true;\n  }\n\n  return false;\n}\n```"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 1906, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 264, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 2170}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6930b3dd17008190adb81627aa00b1e1", "custom_id": "req-0003", "response": {"status_code": 200, "request_id": "bf994266b17ba2dc27b5520f8392492e", "body": {"id": "resp_06d901af4e0401e7006930b3cde280819885d9a61d4f26685b", "object": "response", "created_at": 1764799438, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4o-2024-08-06", "output": [{"id": "msg_06d901af4e0401e7006930b3d3c7a08198a2a9ab728b41fecb", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "```c\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  if (solver->stable) {\n    if (kissat_reluctant_triggered(&solver->reluctant))\n      return true;\n    double current_reward = solver->mab_reward[solver->heuristic];\n    double max_reward = fmax(solver->mab_reward[0], solver->mab_reward[1]);\n    if (current_reward < 0.8 * max_reward)\n      return true;\n  } else {\n    double fast = AVERAGE(fast_glue);\n    double slow = AVERAGE(slow_glue);\n    double margin = (100.0 + GET_OPTION(restartmargin)) / 100.0;\n    double limit = margin * slow;\n    if (limit <= fast)\n      return true;\n    if (AVERAGE(decision_rate) < 1.0)\n      return true;\n  }\n\n  return false;\n}\n```"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 1906, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 246, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 2152}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6930b3dd584881908659d75d0af717f1", "custom_id": "req-0004", "response": {"status_code": 200, "request_id": "f98325a48e1e779d846d7b92899e81f9", "body": {"id": "resp_04801ac05959346c006930b3cddb00819990d7ba1843c42f88", "object": "response", "created_at": 1764799437, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4o-2024-08-06", "output": [{"id": "msg_04801ac05959346c006930b3cee96881999d5e27bfc25b82af", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  if (solver->stable) {\n    if (kissat_reluctant_triggered(&solver->reluctant))\n      return true;\n\n    double current_reward = solver->mab_reward[solver->heuristic];\n    double max_reward = 0.0;\n    unsigned selection_count = solver->mab_select[solver->heuristic];\n\n    if (selection_count > 0)\n      max_reward = current_reward / selection_count;\n\n    if (current_reward < 0.8 * max_reward)\n      return true;\n\n    return false;\n  } else {\n    const double fast = AVERAGE(fast_glue);\n    const double slow = AVERAGE(slow_glue);\n    const double margin = (100.0 + GET_OPTION(restartmargin)) / 100.0;\n    const double limit = margin * slow;\n\n    if (limit <= fast)\n      return true;\n\n    const double decision_rate = AVERAGE(decision_rate);\n    return decision_rate < 1.0;\n  }\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 1906, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 277, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 2183}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6930b3dd2aec8190bd1cbd5591a7782d", "custom_id": "req-0005", "response": {"status_code": 200, "request_id": "d127e018e7be097397b0bcea6899b359", "body": {"id": "resp_00059ba21ca85a1f006930b3cde38c819987d270a716d6a30f", "object": "response", "created_at": 1764799437, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4o-2024-08-06", "output": [{"id": "msg_00059ba21ca85a1f006930b3ceb10481998deb22feb55bb87f", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "```c\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  if (solver->stable) {\n    if (kissat_reluctant_triggered(&solver->reluctant))\n      return true;\n\n    double current_reward = (solver->heuristic == 0) ? solver->mab_reward[0] : solver->mab_reward[1];\n    double max_reward = fmax(solver->mab_reward[0], solver->mab_reward[1]);\n    if (current_reward < 0.8 * max_reward)\n      return true;\n  } else {\n    const double fast = AVERAGE(fast_glue);\n    const double slow = AVERAGE(slow_glue);\n    const double margin = (100.0 + GET_OPTION(restartmargin)) / 100.0;\n    const double limit = margin * slow;\n\n    if (limit <= fast)\n      return true;\n\n    if (AVERAGE(decision_rate) < 1.0)\n      return true;\n  }\n\n  return false;\n}\n```"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 1906, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 266, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 2172}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6930b3dd348881909cd0d2150781b7a0", "custom_id": "req-0006", "response": {"status_code": 200, "request_id": "f234e52785fd3598a3699a0d377471c7", "body": {"id": "resp_0ea05d360623b6ee006930b3d2df9881988e26e2750d08dc8b", "object": "response", "created_at": 1764799442, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4o-2024-08-06", "output": [{"id": "msg_0ea05d360623b6ee006930b3d365788198b5788a12e3142f36", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "```c\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n  \n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  if (solver->stable) {\n    if (kissat_reluctant_triggered(&solver->reluctant))\n      return true;\n    double current_reward = solver->mab_reward[solver->heuristic];\n    double max_reward = current_reward > solver->mab_reward[1 - solver->heuristic] ? current_reward : solver->mab_reward[1 - solver->heuristic];\n    if (current_reward < 0.8 * max_reward)\n      return true;\n  } else {\n    const double fast = AVERAGE(fast_glue);\n    const double slow = AVERAGE(slow_glue);\n    const double margin = (100.0 + GET_OPTION(restartmargin)) / 100.0;\n    const double limit = margin * slow;\n    if (limit <= fast)\n      return true;\n    if (AVERAGE(decision_rate) < 1.0)\n      return true;\n  }\n\n  return false;\n}\n```"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 1906, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 265, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 2171}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6930b3dd2aa88190bc0132dd9b68bf67", "custom_id": "req-0007", "response": {"status_code": 200, "request_id": "5bff8908e38359b4dbe1aa5709c431e4", "body": {"id": "resp_065db514a377a004006930b3917c78819b88433bae6d6675f2", "object": "response", "created_at": 1764799377, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4o-2024-08-06", "output": [{"id": "msg_065db514a377a004006930b39357dc819bbc49a3d55ba071bc", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "<code>\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  if (solver->stable) {\n    if (kissat_reluctant_triggered(&solver->reluctant))\n      return true;\n    double max_reward = fmax(solver->mab_reward[0], solver->mab_reward[1]);\n    if (solver->heuristic == 0 && solver->mab_reward[0] < 0.8 * max_reward)\n      return true;\n    if (solver->heuristic == 1 && solver->mab_reward[1] < 0.8 * max_reward)\n      return true;\n  } else {\n    double fast = AVERAGE(fast_glue);\n    double slow = AVERAGE(slow_glue);\n    double margin = (100.0 + GET_OPTION(restartmargin)) / 100.0;\n    double limit = margin * slow;\n    if (limit <= fast)\n      return true;\n    if (AVERAGE(decision_rate) < 1.0)\n      return true;\n  }\n\n  return false;\n}\n</code>"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 1906, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 278, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 2184}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6930b3dd6ee48190a93f17314e88a8c2", "custom_id": "req-0008", "response": {"status_code": 200, "request_id": "d7f10e1c8908dccc36a4c00be7faa137", "body": {"id": "resp_074fa19724f7a14a006930b3d36ccc81989872c67fedbda00d", "object": "response", "created_at": 1764799443, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4o-2024-08-06", "output": [{"id": "msg_074fa19724f7a14a006930b3d40fd0819893a3ae9d80e50fd3", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "```c\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  const double decision_rate_threshold = 1.0;\n  if (AVERAGE(decision_rate) < decision_rate_threshold)\n    return true;\n\n  if (solver->stable) {\n    if (kissat_reluctant_triggered(&solver->reluctant))\n      return true;\n\n    unsigned heuristic = solver->heuristic;\n    double current_reward = solver->mab_reward[heuristic];\n    double max_reward = solver->mab_reward[heuristic] / 0.8; // Recalculate max_reward\n    if (current_reward < 0.8 * max_reward)\n      return true;\n\n    return false;\n  }\n\n  const double fast = AVERAGE(fast_glue);\n  const double slow = AVERAGE(slow_glue);\n  const double margin = (100.0 + GET_OPTION(restartmargin)) / 100.0;\n  const double limit = margin * slow;\n  return (limit <= fast);\n}\n```"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 1906, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 262, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 2168}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6930b3dd3074819089e9597287db4821", "custom_id": "req-0009", "response": {"status_code": 200, "request_id": "51da0f922b9146c83a660db2637fabf7", "body": {"id": "resp_012b945159c9d843006930b3d4581c81988502a869b50e72f8", "object": "response", "created_at": 1764799444, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4o-2024-08-06", "output": [{"id": "msg_012b945159c9d843006930b3d4e16481988c274624996c45d7", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "```c\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  if (solver->stable) {\n    double current_reward = solver->mab_reward[solver->heuristic];\n    double max_reward = fmax(solver->mab_reward[0], solver->mab_reward[1]);\n    if (current_reward < 0.8 * max_reward)\n      return true;\n    return kissat_reluctant_triggered(&solver->reluctant);\n  }\n\n  const double fast = AVERAGE(fast_glue);\n  const double slow = AVERAGE(slow_glue);\n  const double margin = (100.0 + GET_OPTION(restartmargin)) / 100.0;\n  const double limit = margin * slow;\n\n  if (limit <= fast)\n    return true;\n\n  const double decision_rate_threshold = 1.0;\n  if (AVERAGE(decision_rate) < decision_rate_threshold)\n    return true;\n\n  return false;\n}\n```"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 1906, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 252, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 2158}, "user": null, "metadata": {}}}, "error": null}
{"id": "batch_req_6930b3dd26888190b5c36bdc0086a339", "custom_id": "req-0010", "response": {"status_code": 200, "request_id": "2179c768d3a54dd3be2a158d50b78cd1", "body": {"id": "resp_02ae683581df1dd6006930b3d78864819a9d0e71e8494b49a2", "object": "response", "created_at": 1764799447, "status": "completed", "background": false, "billing": {"payer": "developer"}, "error": null, "incomplete_details": null, "instructions": null, "max_output_tokens": null, "max_tool_calls": null, "model": "gpt-4o-2024-08-06", "output": [{"id": "msg_02ae683581df1dd6006930b3d814a8819aa106a7bc3f836fc4", "type": "message", "status": "completed", "content": [{"type": "output_text", "annotations": [], "logprobs": [], "text": "```c\nbool kissat_restarting(kissat *solver) {\n  assert(solver->unassigned);\n\n  if (!GET_OPTION(restart))\n    return false;\n  if (!solver->level)\n    return false;\n  if (CONFLICTS < solver->limits.restart.conflicts)\n    return false;\n\n  if (solver->stable) {\n    if (kissat_reluctant_triggered(&solver->reluctant))\n      return true;\n\n    double current_reward = solver->heuristic ? solver->mab_reward[1] : solver->mab_reward[0];\n    double max_reward = solver->heuristic ? solver->mab_reward[1] : solver->mab_reward[0];\n    if (current_reward < 0.8 * max_reward)\n      return true;\n\n    return false;\n  }\n\n  const double fast = AVERAGE(fast_glue);\n  const double slow = AVERAGE(slow_glue);\n  const double margin = (100.0 + GET_OPTION(restartmargin)) / 100.0;\n  const double limit = margin * slow;\n\n  if (limit <= fast)\n    return true;\n\n  if (AVERAGE(decision_rate) < 1.0)\n    return true;\n\n  return false;\n}\n```"}], "role": "assistant"}], "parallel_tool_calls": true, "previous_response_id": null, "prompt_cache_key": null, "prompt_cache_retention": null, "reasoning": {"effort": null, "summary": null}, "safety_identifier": null, "service_tier": "default", "store": true, "temperature": 0.7, "text": {"format": {"type": "text"}, "verbosity": "medium"}, "tool_choice": "auto", "tools": [], "top_logprobs": 0, "top_p": 1.0, "truncation": "disabled", "usage": {"input_tokens": 1906, "input_tokens_details": {"cached_tokens": 0}, "output_tokens": 264, "output_tokens_details": {"reasoning_tokens": 0}, "total_tokens": 2170}, "user": null, "metadata": {}}}, "error": null}
