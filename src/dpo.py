import torch
import torch.distributed as dist
import logging
import warnings
from transformers import AutoTokenizer, AutoModelForCausalLM
from trl import DPOTrainer, DPOConfig
from datasets import load_dataset
from torch.utils.data import DataLoader
import wandb
import os
import gc
import time
from utils import get_gpu_memory_info, force_cleanup_gpu, log_memory_usage, logger
from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training
from accelerate import Accelerator, DataLoaderConfiguration
from data_manager import DataManager

# ä¼˜åŒ–è®¾ç½®
torch.set_float32_matmul_precision('high')  # å¯ç”¨ TensorFloat32 ä¼˜åŒ–

# æŠ‘åˆ¶ä¸€äº›ä¸é‡è¦çš„è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="torch._inductor")
warnings.filterwarnings("ignore", message=".*tensor cores for float32 matrix multiplication.*")
warnings.filterwarnings("ignore", message=".*FSDP upcast of low precision parameters.*")
warnings.filterwarnings("ignore", message=".*TypedStorage is deprecated.*")


dataloader_config = DataLoaderConfiguration(dispatch_batches=True, split_batches=True)
accelerator = Accelerator(dataloader_config=dataloader_config)


# --- å…¨å±€å‚æ•° ---
n_epochs = 1
beta = 0.1
lr = 2e-5
warmup_steps = 10
accumulation_steps=1
n_of_gpus = 4
lora_r = 32
per_device_batch_size = 32           # è¿™æ˜¯ per_device_batch_size
data_size = 1000
data_size = per_device_batch_size * n_of_gpus * 10
max_steps = data_size // per_device_batch_size
data_file_path = "./dataset/dataset_preprocessed.jsonl" 


# åˆå§‹åŒ–wandb
def init_wandb(lora_r=16, lora_alpha=32, lora_dropout=0.1, batch_size=1):
    """åˆå§‹åŒ–wandb"""
    try:
        # ä»ç¯å¢ƒå˜é‡æˆ–ç›´æ¥è®¾ç½®APIå¯†é’¥
        api_key = os.getenv("WANDB_API_KEY", "2b12ed4713d66c27d43040761ff1e0574c7a7ef2")
        wandb.login(key=api_key)
        
        # åˆå§‹åŒ–wandbé¡¹ç›®
        wandb.init(
            project="gpt-oss-dpo",
            name="dpo-lora-training",
            config={
                "model": f"gpt-oss-20b_bs{batch_size}_r{lora_r}_alpha{lora_alpha}_dropout{lora_dropout}",
                "method": "DPO+LoRA",
                "learning_rate": lr,
                "batch_size": batch_size,
                "epochs": n_epochs,
                "beta": beta,
                "lora_r": lora_r,
                "lora_alpha": lora_alpha,
                "lora_dropout": lora_dropout,
            }
        )
        logger.info("âœ… Wandbåˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        logger.warning(f"âš ï¸ Wandbåˆå§‹åŒ–å¤±è´¥: {e}")
        return False

def run_training(lora_r=16, lora_alpha=32, lora_dropout=0.1):
    model_name = "./models/gpt-oss-20b"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    dpo_config = DPOConfig(
        output_dir=f"./gpt_oss_dpo_output_bs{per_device_batch_size}",
        # num_train_epochs=n_epochs,
        max_steps=10,
        per_device_train_batch_size=per_device_batch_size,
        per_device_eval_batch_size=per_device_batch_size,
        warmup_steps=warmup_steps,
        logging_steps=1,
        save_steps=50,
        save_strategy="steps",
        save_safetensors=False,  # ç¦ç”¨ safetensors ä¿å­˜æ ¼å¼
        remove_unused_columns=False,
        max_length=2048,
        beta=beta,
        learning_rate=lr,
        lr_scheduler_type="cosine",
        local_rank=int(os.environ.get("LOCAL_RANK", -1)),
        ddp_find_unused_parameters=False,
        gradient_accumulation_steps=accumulation_steps,
        gradient_checkpointing=False,
        bf16=True,
        dataloader_drop_last=True,
        dataloader_num_workers=0,
        padding_value=tokenizer.pad_token_id,
        # æ·»åŠ å†…å­˜ç®¡ç†ç›¸å…³é…ç½®
        dataloader_pin_memory=False,
        dataloader_persistent_workers=False,
    )
    is_main_process = dpo_config.local_rank in [-1, 0]
    if is_main_process:
        logger.info("ğŸš€ start training...")
        wandb_enabled = init_wandb(lora_r, lora_alpha, lora_dropout, per_device_batch_size)
        log_memory_usage("after model loading", wandb_enabled)
    else:
        wandb_enabled = False
    
    force_cleanup_gpu()
    
    log_memory_usage("Initial state", wandb_enabled)
    
    
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.bfloat16,
        # device_map={"": dpo_config.local_rank},
        trust_remote_code=True,
    )
    # model = prepare_model_for_kbit_training(model)
    # è®¾ç½®LoRA
    lora_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        r=lora_r,
        lora_alpha=lora_alpha,
        lora_dropout=lora_dropout,
        target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
        bias="none",
    )
    
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()
    
    # è®°å½•LoRAåº”ç”¨åå†…å­˜çŠ¶æ€
    log_memory_usage("after LoRA application", wandb_enabled)
    
    data_file_path = "./dataset/dataset_preprocessed.jsonl" # <-- æ›¿æ¢æˆä½ çš„æ•°æ®æ–‡ä»¶è·¯å¾„
    # åŠ è½½æ•°æ®é›†
    train_dataset = load_dataset("json", data_files=data_file_path, split="train", streaming=False)
    # é™åˆ¶æ•°æ®å¤§å°ç”¨äºæµ‹è¯•
    train_dataset = train_dataset.take(data_size)
    results = []
    
    logger.info(f"ğŸ§ª test batch_size = {per_device_batch_size}")
    
    try:
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        gc.collect()
        
        memory_before = log_memory_usage(f"batch_{per_device_batch_size}_before", wandb_enabled)
        
        
        # åˆ›å»ºDPOè®­ç»ƒå™¨
        dpo_trainer = DPOTrainer(
            model=model,
            ref_model=None,
            args=dpo_config,
            train_dataset=train_dataset,
        )
        
        memory_trainer = log_memory_usage(f"batch_{per_device_batch_size}_trainer_created", wandb_enabled)
        
        # å¼€å§‹è®­ç»ƒ
        start_time = time.time()
        try:
            dpo_trainer.train()
            training_time = time.time() - start_time
        except Exception as train_error:
            logger.warning(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œä½†å¯èƒ½å·²å®Œæˆ: {train_error}")
            training_time = time.time() - start_time
            # æ£€æŸ¥æ˜¯å¦è‡³å°‘å®Œæˆäº†ä¸€äº›æ­¥éª¤
            if hasattr(dpo_trainer.state, 'global_step') and dpo_trainer.state.global_step > 0:
                logger.info(f"è®­ç»ƒéƒ¨åˆ†å®Œæˆï¼Œå·²å®Œæˆ {dpo_trainer.state.global_step} æ­¥")
            else:
                raise train_error
        
        memory_after = log_memory_usage(f"batch_{per_device_batch_size}_after_training", wandb_enabled)
        
        # è®°å½•ç»“æœ
        result = {
            "lora_r": lora_r,
            "lora_alpha": lora_alpha,
            "lora_dropout": lora_dropout,
            "batch_size": per_device_batch_size,
            "training_time": training_time,
            "memory_before": memory_before,
            "memory_trainer": memory_trainer,
            "memory_after": memory_after,
            "success": True
        }
        results.append(result)
        
        logger.info(f"âœ… Batch size {per_device_batch_size} è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
        
        # æ¸…ç†å†…å­˜
        del dpo_trainer
        torch.cuda.empty_cache()
        gc.collect()
        
    except Exception as e:
        logger.error(f"âŒ Batch size {per_device_batch_size} è®­ç»ƒå¤±è´¥: {e}")
        result = {
            "batch_size": per_device_batch_size,
            "error": str(e),
            "success": False
        }
        results.append(result)
        
        # æ¸…ç†å†…å­˜
        torch.cuda.empty_cache()
        gc.collect()
    
    # è¾“å‡ºæµ‹è¯•ç»“æœæ€»ç»“
    if is_main_process:
        logger.info("ğŸ“Š Batch Size æµ‹è¯•ç»“æœæ€»ç»“:")
        logger.info("=" * 80)
        for result in results:
            if result["success"]:
                logger.info(f"Batch Size {result['batch_size']:2d}: âœ… æˆåŠŸ - "
                        f"è®­ç»ƒæ—¶é—´: {result['training_time']:6.2f}s - "
                        f"GPUåˆ©ç”¨ç‡: {result['memory_after']['gpu_utilization_pct']:5.1f}% - "
                        f"GPUä½¿ç”¨: {result['memory_after']['gpu_reserved_gb']:5.1f}GB")
            else:
                logger.info(f"Batch Size {result['batch_size']:2d}: âŒ å¤±è´¥ - {result['error']}")
    
    # è®°å½•åˆ°wandb
    if wandb_enabled:
        for result in results:
            if result["success"]:
                wandb.log({
                    "batch_size": result["batch_size"],
                    "training_time": result["training_time"],
                    "gpu_utilization_pct": result["memory_after"]["gpu_utilization_pct"],
                    "gpu_reserved_gb": result["memory_after"]["gpu_reserved_gb"],
                    "test_success": True
                })
            else:
                wandb.log({
                    "batch_size": result["batch_size"],
                    "error": result["error"],
                    "test_success": False
                })
    
    # æœ€ç»ˆå†…å­˜çŠ¶æ€
    log_memory_usage("æµ‹è¯•å®Œæˆ", wandb_enabled)
    
    # å½»åº•æ¸…ç†æ˜¾å­˜
    try:
        del model
        del tokenizer
        del train_dataset
        if 'dpo_trainer' in locals():
            del dpo_trainer
    except:
        pass
    
    force_cleanup_gpu()
    
    # è®°å½•æ¸…ç†åå†…å­˜çŠ¶æ€
    log_memory_usage("æ¸…ç†å", wandb_enabled)
    
    return results

def main():
    logger.info("å¼€å§‹gpt-oss-20b DPO+LoRA batch sizeæµ‹è¯•...")
    
    config =  {"lora_r": lora_r, "lora_alpha": 2 * lora_r, "lora_dropout": 0.1}
    
    all_results = []
    
    logger.info(f"ğŸ”„ start training with config: {config}")
    force_cleanup_gpu()
    
    try:
        results = run_training(**config)
        all_results.extend(results)

    except Exception as e:
        logger.error(f"âŒ training failed: {e}")
        all_results.append({
            "config": config,
            "error": str(e),
            "success": False
        })

    # è¾“å‡ºæ‰€æœ‰æµ‹è¯•ç»“æœæ€»ç»“
    logger.info("ğŸ“Š all results summary:")
    logger.info("=" * 100)
    for i, result in enumerate(all_results):
        if result.get("success", False):
            logger.info(f"æµ‹è¯• {i+1}: LoRA r={result['lora_r']}ï¼Œalpha={result['lora_alpha']}ï¼Œdropout={result['lora_dropout']}ï¼Œbatch_size={result['batch_size']} - âœ… æˆåŠŸ - "
                        f"è®­ç»ƒæ—¶é—´: {result['training_time']:6.2f}s - "
                        f"GPUåˆ©ç”¨ç‡: {result['memory_after']['gpu_utilization_pct']:5.1f}% - "
                        f"GPUä½¿ç”¨: {result['memory_after']['gpu_reserved_gb']:5.1f}GB")
        else:
            logger.info(f"æµ‹è¯• {i+1}: âŒ å¤±è´¥ - {result.get('error', 'Unknown error')}")
    

if __name__ == "__main__":
    main()

